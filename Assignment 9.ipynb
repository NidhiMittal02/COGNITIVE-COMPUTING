{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c2ede3-313f-4488-8065-553006a1efa6",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "### Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports, technology, food, books, etc.).\n",
    "1. Convert text to lowercase and remove punctuaƟon.\n",
    "2. Tokenize the text into words and sentences.\n",
    "3. Remove stopwords (using NLTK's stopwords list).\n",
    "4. Display word frequency distribuƟon (excluding stopwords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe0056b-d290-4f14-bb39-9684e86fdda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\91995\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\91995\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\91995\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\91995\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\91995\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\91995\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: C:\\Users\\91995\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab118907-6830-4a80-b3b5-db101ec4f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"\n",
    "Oceans cover more than 70% of the Earth's surface and play a critical role in sustaining life. They regulate the planet's climate, produce over half of the world's oxygen, and support a rich diversity of marine life. Oceans also provide food, jobs, and recreational opportunities for millions of people. Coral reefs, often called the rainforests of the sea, are vital ecosystems that protect coastlines and host thousands of species. However, pollution, overfishing, and climate change are threatening ocean health. Protecting our oceans is essential for maintaining the balance of life on Earth.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3cd1155-77b3-41d6-902e-b4513ec1950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "oceans cover more than 70 of the earths surface and play a critical role in sustaining life they regulate the planets climate produce over half of the worlds oxygen and support a rich diversity of marine life oceans also provide food jobs and recreational opportunities for millions of people coral reefs often called the rainforests of the sea are vital ecosystems that protect coastlines and host thousands of species however pollution overfishing and climate change are threatening ocean health protecting our oceans is essential for maintaining the balance of life on earth\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "text_low = sentence.lower()\n",
    "no_punc = text_low.translate(str.maketrans('', '', string.punctuation))\n",
    "print(no_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e71e258-fca7-45b3-8601-f8a994fc4ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91995\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2519cfc0-eacc-430e-bff6-12762151e505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized words:   ['oceans', 'cover', 'more', 'than', '70', 'of', 'the', 'earths', 'surface', 'and', 'play', 'a', 'critical', 'role', 'in', 'sustaining', 'life', 'they', 'regulate', 'the', 'planets', 'climate', 'produce', 'over', 'half', 'of', 'the', 'worlds', 'oxygen', 'and', 'support', 'a', 'rich', 'diversity', 'of', 'marine', 'life', 'oceans', 'also', 'provide', 'food', 'jobs', 'and', 'recreational', 'opportunities', 'for', 'millions', 'of', 'people', 'coral', 'reefs', 'often', 'called', 'the', 'rainforests', 'of', 'the', 'sea', 'are', 'vital', 'ecosystems', 'that', 'protect', 'coastlines', 'and', 'host', 'thousands', 'of', 'species', 'however', 'pollution', 'overfishing', 'and', 'climate', 'change', 'are', 'threatening', 'ocean', 'health', 'protecting', 'our', 'oceans', 'is', 'essential', 'for', 'maintaining', 'the', 'balance', 'of', 'life', 'on', 'earth'] \n",
      "\n",
      "Tokenized Sentences:   [\"\\nOceans cover more than 70% of the Earth's surface and play a critical role in sustaining life.\", \"They regulate the planet's climate, produce over half of the world's oxygen, and support a rich diversity of marine life.\", 'Oceans also provide food, jobs, and recreational opportunities for millions of people.', 'Coral reefs, often called the rainforests of the sea, are vital ecosystems that protect coastlines and host thousands of species.', 'However, pollution, overfishing, and climate change are threatening ocean health.', 'Protecting our oceans is essential for maintaining the balance of life on Earth.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(no_punc)\n",
    "sent = sent_tokenize(sentence)\n",
    "print(\"Tokenized words:  \", words,\"\\n\")\n",
    "print(\"Tokenized Sentences:  \", sent,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35b03bed-d826-4e1b-8b09-6bc742c95667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopper = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16f21f29-e0f5-425b-ad6b-97feb0757d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Word Tokens:\n",
      " ['oceans', 'cover', '70', 'earths', 'surface', 'play', 'critical', 'role', 'sustaining', 'life', 'regulate', 'planets', 'climate', 'produce', 'half', 'worlds', 'oxygen', 'support', 'rich', 'diversity', 'marine', 'life', 'oceans', 'also', 'provide', 'food', 'jobs', 'recreational', 'opportunities', 'millions', 'people', 'coral', 'reefs', 'often', 'called', 'rainforests', 'sea', 'vital', 'ecosystems', 'protect', 'coastlines', 'host', 'thousands', 'species', 'however', 'pollution', 'overfishing', 'climate', 'change', 'threatening', 'ocean', 'health', 'protecting', 'oceans', 'essential', 'maintaining', 'balance', 'life', 'earth'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stopper_removed = [w for w in words if w not in stopper]\n",
    "print(\"Filtered Word Tokens:\\n\", stopper_removed ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04b7aa6f-0141-43ef-8c21-ac3fe7a8e75f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Frequency Distribution:\n",
      "oceans: 3\n",
      "cover: 1\n",
      "70: 1\n",
      "earths: 1\n",
      "surface: 1\n",
      "play: 1\n",
      "critical: 1\n",
      "role: 1\n",
      "sustaining: 1\n",
      "life: 3\n",
      "regulate: 1\n",
      "planets: 1\n",
      "climate: 2\n",
      "produce: 1\n",
      "half: 1\n",
      "worlds: 1\n",
      "oxygen: 1\n",
      "support: 1\n",
      "rich: 1\n",
      "diversity: 1\n",
      "marine: 1\n",
      "also: 1\n",
      "provide: 1\n",
      "food: 1\n",
      "jobs: 1\n",
      "recreational: 1\n",
      "opportunities: 1\n",
      "millions: 1\n",
      "people: 1\n",
      "coral: 1\n",
      "reefs: 1\n",
      "often: 1\n",
      "called: 1\n",
      "rainforests: 1\n",
      "sea: 1\n",
      "vital: 1\n",
      "ecosystems: 1\n",
      "protect: 1\n",
      "coastlines: 1\n",
      "host: 1\n",
      "thousands: 1\n",
      "species: 1\n",
      "however: 1\n",
      "pollution: 1\n",
      "overfishing: 1\n",
      "change: 1\n",
      "threatening: 1\n",
      "ocean: 1\n",
      "health: 1\n",
      "protecting: 1\n",
      "essential: 1\n",
      "maintaining: 1\n",
      "balance: 1\n",
      "earth: 1\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "frequency_dist = FreqDist(stopper_removed)\n",
    "print(\"\\nWord Frequency Distribution:\")\n",
    "for word, frequency in frequency_dist.items():\n",
    "    print(f\"{word}: {frequency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910039f1-ab9c-4a29-8c5a-8c3f1a488b4c",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "### Stemming and Lemmatization\n",
    "1. Take the tokenized words from QuesƟon 1 (aŌer stopword removal).\n",
    "2. Apply stemming using NLTK's PorterStemmer and LancasterStemmer.\n",
    "3. Apply lemmaƟzaƟon using NLTK's WordNetLemmaƟzer.\n",
    "4. Compare and display results of both techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d73d1f7d-bb88-40a6-9eda-13bd1452b3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4') \n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "portered = [porter.stem(w) for w in stopper_removed]\n",
    "lancastered = [lancaster.stem(w) for w in stopper_removed]\n",
    "lemmatized = [lemmatizer.lemmatize(w) for w in stopper_removed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dcdf1ec-56fc-496e-8efc-491dd2089bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original            Porter              Lancaster           Lemma              \n",
      "------------------------------------------------------------\n",
      "oceans              ocean               oc                  ocean              \n",
      "cover               cover               cov                 cover              \n",
      "70                  70                  70                  70                 \n",
      "earths              earth               earth               earth              \n",
      "surface             surfac              surfac              surface            \n",
      "play                play                play                play               \n",
      "critical            critic              crit                critical           \n",
      "role                role                rol                 role               \n",
      "sustaining          sustain             sustain             sustaining         \n",
      "life                life                lif                 life               \n",
      "regulate            regul               reg                 regulate           \n",
      "planets             planet              planet              planet             \n",
      "climate             climat              clim                climate            \n",
      "produce             produc              produc              produce            \n",
      "half                half                half                half               \n",
      "worlds              world               world               world              \n",
      "oxygen              oxygen              oxyg                oxygen             \n",
      "support             support             support             support            \n",
      "rich                rich                rich                rich               \n",
      "diversity           divers              divers              diversity          \n",
      "marine              marin               marin               marine             \n",
      "life                life                lif                 life               \n",
      "oceans              ocean               oc                  ocean              \n",
      "also                also                also                also               \n",
      "provide             provid              provid              provide            \n",
      "food                food                food                food               \n",
      "jobs                job                 job                 job                \n",
      "recreational        recreat             recr                recreational       \n",
      "opportunities       opportun            opportun            opportunity        \n",
      "millions            million             mil                 million            \n",
      "people              peopl               peopl               people             \n",
      "coral               coral               cor                 coral              \n",
      "reefs               reef                reef                reef               \n",
      "often               often               oft                 often              \n",
      "called              call                cal                 called             \n",
      "rainforests         rainforest          rainforest          rainforest         \n",
      "sea                 sea                 sea                 sea                \n",
      "vital               vital               vit                 vital              \n",
      "ecosystems          ecosystem           ecosystem           ecosystem          \n",
      "protect             protect             protect             protect            \n",
      "coastlines          coastlin            coastlin            coastline          \n",
      "host                host                host                host               \n",
      "thousands           thousand            thousand            thousand           \n",
      "species             speci               specy               specie             \n",
      "however             howev               howev               however            \n",
      "pollution           pollut              pollut              pollution          \n",
      "overfishing         overfish            overf               overfishing        \n",
      "climate             climat              clim                climate            \n",
      "change              chang               chang               change             \n",
      "threatening         threaten            threatening         threatening        \n",
      "ocean               ocean               oc                  ocean              \n",
      "health              health              heal                health             \n",
      "protecting          protect             protect             protecting         \n",
      "oceans              ocean               oc                  ocean              \n",
      "essential           essenti             ess                 essential          \n",
      "maintaining         maintain            maintain            maintaining        \n",
      "balance             balanc              bal                 balance            \n",
      "life                life                lif                 life               \n",
      "earth               earth               ear                 earth              \n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Original':<19} {'Porter':<19} {'Lancaster':<19} {'Lemma':<19}\")\n",
    "print(\"-\" * 60)\n",
    "for o, p, l, le in zip(stopper_removed, portered, lancastered, lemmatized):\n",
    "    print(\"{:<19} {:<19} {:<19} {:<19}\".format(o, p, l, le))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f3f33a-5e64-4d4b-8ae4-6ce4e8665250",
   "metadata": {},
   "source": [
    "# Question 3. Regular Expressions and Text Spliƫng\n",
    "1. Take their original text from Question 1.\n",
    "2. Use regular expressions to:\n",
    " \n",
    "    - a. Extract all words with more than 5 letters.\n",
    " \n",
    "    - b. Extract all numbers (if any exist in their text).\n",
    " \n",
    "    - c. Extract all capitalized words.\n",
    "3. Use text spliƫng techniques to:\n",
    "   \n",
    "    - a. Split the text into words containing only alphabets (removing digits and specialcharacters).\n",
    "    - b. Extract words starting with a vowel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c9b492d-7dfb-492d-9182-135ac4aedc5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words (>5) letters:   ['oceans', 'earths', 'surface', 'critical', 'sustaining', 'regulate', 'planets', 'climate', 'produce', 'worlds', 'oxygen', 'support', 'diversity', 'marine', 'oceans', 'provide', 'recreational', 'opportunities', 'millions', 'people', 'called', 'rainforests', 'ecosystems', 'protect', 'coastlines', 'thousands', 'species', 'however', 'pollution', 'overfishing', 'climate', 'change', 'threatening', 'health', 'protecting', 'oceans', 'essential', 'maintaining', 'balance'] \n",
      "\n",
      "\n",
      "Numbers :   ['70'] \n",
      "\n",
      "\n",
      "Capitalized :   ['Oceans', 'Earth', 'They', 'Oceans', 'Coral', 'However', 'Protecting', 'Earth'] \n",
      "\n",
      "\n",
      "Only alpha words:   ['oceans', 'cover', 'more', 'than', 'of', 'the', 'earths', 'surface', 'and', 'play', 'a', 'critical', 'role', 'in', 'sustaining', 'life', 'they', 'regulate', 'the', 'planets', 'climate', 'produce', 'over', 'half', 'of', 'the', 'worlds', 'oxygen', 'and', 'support', 'a', 'rich', 'diversity', 'of', 'marine', 'life', 'oceans', 'also', 'provide', 'food', 'jobs', 'and', 'recreational', 'opportunities', 'for', 'millions', 'of', 'people', 'coral', 'reefs', 'often', 'called', 'the', 'rainforests', 'of', 'the', 'sea', 'are', 'vital', 'ecosystems', 'that', 'protect', 'coastlines', 'and', 'host', 'thousands', 'of', 'species', 'however', 'pollution', 'overfishing', 'and', 'climate', 'change', 'are', 'threatening', 'ocean', 'health', 'protecting', 'our', 'oceans', 'is', 'essential', 'for', 'maintaining', 'the', 'balance', 'of', 'life', 'on', 'earth'] \n",
      "\n",
      "Only alpha words:\n",
      " ['oceans', 'cover', 'more', 'than', 'of', 'the', 'earths', 'surface', 'and', 'play', 'a', 'critical', 'role', 'in', 'sustaining', 'life', 'they', 'regulate', 'the', 'planets', 'climate', 'produce', 'over', 'half', 'of', 'the', 'worlds', 'oxygen', 'and', 'support', 'a', 'rich', 'diversity', 'of', 'marine', 'life', 'oceans', 'also', 'provide', 'food', 'jobs', 'and', 'recreational', 'opportunities', 'for', 'millions', 'of', 'people', 'coral', 'reefs', 'often', 'called', 'the', 'rainforests', 'of', 'the', 'sea', 'are', 'vital', 'ecosystems', 'that', 'protect', 'coastlines', 'and', 'host', 'thousands', 'of', 'species', 'however', 'pollution', 'overfishing', 'and', 'climate', 'change', 'are', 'threatening', 'ocean', 'health', 'protecting', 'our', 'oceans', 'is', 'essential', 'for', 'maintaining', 'the', 'balance', 'of', 'life', 'on', 'earth']\n",
      "\n",
      "Words starting with vowels:\n",
      " ['oceans', 'of', 'earths', 'and', 'a', 'in', 'over', 'of', 'oxygen', 'and', 'a', 'of', 'oceans', 'also', 'and', 'opportunities', 'of', 'often', 'of', 'are', 'ecosystems', 'and', 'of', 'overfishing', 'and', 'are', 'ocean', 'our', 'oceans', 'is', 'essential', 'of', 'on', 'earth']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "letter_5 = re.findall(r'\\b\\w{6,}\\b', no_punc)\n",
    "print(\"words (>5) letters:  \", letter_5 ,'\\n')\n",
    "\n",
    "numb = re.findall(r'\\b\\d+\\b', no_punc)\n",
    "print(\"\\nNumbers :  \", numb,'\\n')\n",
    "\n",
    "caps = re.findall(r'\\b[A-Z][a-zA-Z]*\\b', sentence)\n",
    "print(\"\\nCapitalized :  \", caps, '\\n')\n",
    "\n",
    "alphas = re.findall(r'\\b[a-zA-Z]+\\b', no_punc)\n",
    "print(\"\\nOnly alpha words:  \", alphas, '\\n')\n",
    "\n",
    "words_list = no_punc.split()\n",
    "only_alpha_words = [w for w in words_list if w.isalpha()]\n",
    "print(\"Only alpha words:\\n\", only_alpha_words)\n",
    "\n",
    "vowelss = [w for w in alphas if w[0].lower() in 'aeiou']\n",
    "print(\"\\nWords starting with vowels:\\n\", vowelss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385a84f3-f396-475f-ab62-cdf9f3ea6ed7",
   "metadata": {},
   "source": [
    "# Q4. Custom Tokenization & Regex-based Text Cleaning\n",
    "\n",
    "## Steps:\n",
    "\n",
    "1. **Input**: Use the original text from **Question 1**.\n",
    "\n",
    "2. **Custom Tokenization Function Requirements**:\n",
    "   \n",
    "   - **(a)** Remove punctuation and special symbols, **but keep contractions** (e.g., `\"isn't\"` should remain `\"isn't\"` and not split into `\"is\"` and `\"n't\"`).\n",
    "   \n",
    "   - **(b)** Handle **hyphenated words** as **single tokens** (e.g., `\"state-of-the-art\"` should remain as one token).\n",
    "   \n",
    "   - **(c)** **Tokenize numbers separately**, but **keep decimal numbers intact** (e.g., `\"3.14\"` should remain `\"3.14\"`).\n",
    "\n",
    "3. **Regex Substitutions** (using `re.sub`):\n",
    "\n",
    "   - **(a)** Replace **email addresses** with the placeholder `<EMAIL>`.\n",
    "   \n",
    "   - **(b)** Replace **URLs** with the placeholder `<URL>`.\n",
    "   \n",
    "   - **(c)** Replace **phone numbers** (formats like `123-456-7890` or `+91 9876543210`) with the plceho-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\n",
    "placeholder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ba0f752-0f2b-4d70-b76d-b5b16fd6cc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Tokens:   ['Oceans', 'cover', 'more', 'than', '70', 'of', 'the', \"Earth's\", 'surface', 'and', 'play', 'a', 'critical', 'role', 'in', 'sustaining', 'life', 'They', 'regulate', 'the', \"planet's\", 'climate', 'produce', 'over', 'half', 'of', 'the', \"world's\", 'oxygen', 'and', 'support', 'a', 'rich', 'diversity', 'of', 'marine', 'life', 'Oceans', 'also', 'provide', 'food', 'jobs', 'and', 'recreational', 'opportunities', 'for', 'millions', 'of', 'people', 'Coral', 'reefs', 'often', 'called', 'the', 'rainforests', 'of', 'the', 'sea', 'are', 'vital', 'ecosystems', 'that', 'protect', 'coastlines', 'and', 'host', 'thousands', 'of', 'species', 'However', 'pollution', 'overfishing', 'and', 'climate', 'change', 'are', 'threatening', 'ocean', 'health', 'Protecting', 'our', 'oceans', 'is', 'essential', 'for', 'maintaining', 'the', 'balance', 'of', 'life', 'on', 'Earth'] \n",
      "\n",
      "\n",
      "Text after Regex Substitutions:\n",
      " \n",
      "Oceans cover more than 70% of the Earth's surface and play a critical role in sustaining life. They regulate the planet's climate, produce over half of the world's oxygen, and support a rich diversity of marine life. Oceans also provide food, jobs, and recreational opportunities for millions of people. Coral reefs, often called the rainforests of the sea, are vital ecosystems that protect coastlines and host thousands of species. However, pollution, overfishing, and climate change are threatening ocean health. Protecting our oceans is essential for maintaining the balance of life on Earth.\n"
     ]
    }
   ],
   "source": [
    "def custom_tokens(text):\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s\\-']\", \"\", text)\n",
    "    tokens = re.findall(r\"\\b\\w+(?:[-']\\w+)*\\b\", text)\n",
    "    return tokens\n",
    "customs = custom_tokens(sentence)\n",
    "print(\"\\nCustom Tokens:  \", customs, '\\n')\n",
    "\n",
    "\n",
    "text_replaced = re.sub(r'\\b[\\w.-]+?@\\w+?\\.\\w+?\\b', '<EMAIL>', sentence)\n",
    "\n",
    "text_replaced = re.sub(r'http[s]?://\\S+', '<URL>', text_replaced)\n",
    "\n",
    "text_replaced = re.sub(r'(\\+?\\d{1,2}\\s?)?(\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4})', '<PHONE>', text_replaced)\n",
    "\n",
    "print(\"\\nText after Regex Substitutions:\\n\", text_replaced)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
